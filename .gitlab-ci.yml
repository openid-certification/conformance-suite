# This file is a template, and might need editing before it works on your project.
# Auto DevOps
# This CI/CD configuration provides a standard pipeline for
# * building a Docker image (using a buildpack if necessary),
# * storing the image in the container registry,
# * running tests from a buildpack,
# * running code quality analysis,
# * creating a review app for each topic branch,
# * and continuous deployment to production
#
# In order to deploy, you must have a Kubernetes cluster configured either
# via a project integration, or via group/project variables.
# KUBE_INGRESS_BASE_DOMAIN must also be set as a variable at the group or project
# level, or manually added below.
#
# If you want to deploy to staging first, or enable canary deploys,
# uncomment the relevant jobs in the pipeline below.
#
# If Auto DevOps fails to detect the proper buildpack, or if you want to
# specify a custom buildpack, set a project variable `BUILDPACK_URL` to the
# repository URL of the buildpack.
# e.g. BUILDPACK_URL=https://github.com/heroku/heroku-buildpack-ruby.git#v142
# If you need multiple buildpacks, add a file to your project called
# `.buildpacks` that contains the URLs, one on each line, in order.
# Note: Auto CI does not work with multiple buildpacks yet

image: alpine:latest

variables:
  # KUBE_INGRESS_BASE_DOMAIN is the application deployment domain and should be set as a variable at the group or project level.
  # KUBE_INGRESS_BASE_DOMAIN: domain.example.com
  BASE_HOST_NAME: review-app
  PRODUCTION_HOST: www
  STAGING_HOST: staging
  DEMO_HOST: demo
  LM_JAVA_VERSION: 11
  SONAR_URL: "https://sonarqube.certification.openid.net"

stages:
  - build
  - upload
  - review
  - demo
  - staging
  - canary
  - production
  - test
  - cleanup

include:
  - template: Security/Dependency-Scanning.gitlab-ci.yml
  - template: Security/License-Management.gitlab-ci.yml

.maven: &maven
  image: maven:3-jdk-11
  interruptible: true
  variables:
    MAVEN_CONFIG: $CI_PROJECT_DIR/.m2
    MAVEN_OPTS: "-Duser.home=$CI_PROJECT_DIR"
  cache:
    key: maven
    paths:
      - .m2/

build:
  <<: *maven
  stage: build
  script:
    # Don't compile the tests yet
    - mvn -B -Dmaven.test.skip -Dpmd.skip clean package
  artifacts:
    paths:
      - target/

upload:
  stage: upload
  image: docker:git
  services:
    - docker:dind
  variables:
    DOCKER_DRIVER: overlay2
  script:
    - setup_docker
    - install_build_dependencies
    - docker build -t conformance-suite .
    - if [ -n "$GCP_PROJECT_ID" ]; then upload; fi
  dependencies:
    - build

test:
  <<: *maven
  stage: test
  needs: ["build"]
  script:
    # Don't recompile the main app
    - mvn -B -Dmaven.main.skip test
    - |
      perl -ne '/Total.*?(\d+%)/ && print "Unit test coverage $1\n"' target/site/jacoco/index.html
  dependencies:
    - build
  only:
    - branches

check-trailing-whitespace:
  interruptible: true
  stage: build
  image: python:2
  script:
    - ./scripts/checkwhitespace.py
  only:
    - branches

sonarqube_scanner:
  <<: *maven
  stage: test
  needs: ["build"]
  script:
    # Don't compile anything or run tests
    - |
      mvn -B -Dmaven.main.skip -Dmaven.test.skip -Dpmd.skip \
        verify sonar:sonar \
        -Dsonar.host.url=$SONAR_URL \
        -Dsonar.login=$SONAR_LOGIN \
        -Dsonar.analysis.mode=preview \
        -Dsonar.gitlab.commit_sha=$CI_COMMIT_SHA \
        -Dsonar.gitlab.ref_name=$CI_COMMIT_REF_NAME \
        -Dsonar.gitlab.project_id=$CI_PROJECT_PATH \
        -Dsonar.gitlab.unique_issue_per_inline=true \
        -Dsonar.gitlab.url=https://gitlab.com \
        -Dsonar.gitlab.user_token=$SONARQUBE_BOT_API_KEY \
        -Dsonar.gitlab.max_blocker_issues_gate=0 \
        -Dsonar.gitlab.json_mode=SAST \
        -Dsonar.gitlab.failure_notification_mode=exit-code
  dependencies:
    - build
  only:
    - branches

#codequality:
#  image: docker:latest
#  variables:
#    DOCKER_DRIVER: overlay2
#  services:
#    - docker:dind
#  script:
#    - setup_docker
#    - codeclimate
#  artifacts:
#    paths: [codeclimate.json]

.auto-deploy:
  image: "registry.gitlab.com/gitlab-org/cluster-integration/auto-deploy-image:v0.1.0"

review:
  extends: .auto-deploy
  stage: review
  script:
    - auto-deploy check_kube_domain
    - auto-deploy download_chart
    - auto-deploy ensure_namespace
    - auto-deploy initialize_tiller
    - deploy
  environment:
    name: review/$CI_COMMIT_REF_NAME
    url: https://$BASE_HOST_NAME-$CI_COMMIT_REF_SLUG.$KUBE_INGRESS_BASE_DOMAIN
    on_stop: stop_review
  dependencies: []
  only:
    refs:
      - /^dev-branch-[1-9]$/
    kubernetes: active
  except:
    - master
    - production
    - demo

stop_review:
  extends: .auto-deploy
  stage: cleanup
  variables:
    GIT_STRATEGY: none
  script:
    - auto-deploy initialize_tiller
    - auto-deploy delete
  environment:
    name: review/$CI_COMMIT_REF_NAME
    action: stop
  dependencies: []
  when: manual
  allow_failure: true
  only:
    refs:
      - /^dev-branch-[1-9]$/
    kubernetes: active
  except:
    - master
    - production
    - demo

demo:
  extends: .auto-deploy
  stage: demo
  script:
    - auto-deploy check_kube_domain
    - auto-deploy download_chart
    - auto-deploy ensure_namespace
    - auto-deploy initialize_tiller
    - deploy
  environment:
    name: demo
    url: https://$DEMO_HOST.$KUBE_INGRESS_BASE_DOMAIN
  dependencies: []
  only:
    refs:
      - demo
    kubernetes: active

# Keys that start with a dot (.) will not be processed by GitLab CI.
# Staging and canary jobs are disabled by default, to enable them
# remove the dot (.) before the job name.
# https://docs.gitlab.com/ee/ci/yaml/README.html#hidden-keys

# Staging deploys are disabled by default since
# continuous deployment to production is enabled by default
# If you prefer to automatically deploy to staging and
# only manually promote to production, enable this job by removing the dot (.),
# and uncomment the `when: manual` line in the `production` job.

staging:
  extends: .auto-deploy
  stage: staging
  script:
    - auto-deploy check_kube_domain
    - auto-deploy download_chart
    - auto-deploy ensure_namespace
    - auto-deploy initialize_tiller
    - deploy
  environment:
    name: staging
    url: https://$STAGING_HOST.$KUBE_INGRESS_BASE_DOMAIN
  dependencies: []
  only:
    refs:
      - master
    kubernetes: active

# This job continuously deploys to production on every push to `master`.
# To make this a manual process, either because you're enabling `staging`
# or `canary` deploys, or you simply want more control over when you deploy
# to production, uncomment the `when: manual` line in the `production` job.

production:
  extends: .auto-deploy
  stage: production
  script:
    - auto-deploy check_kube_domain
    - auto-deploy download_chart
    - auto-deploy ensure_namespace
    - auto-deploy initialize_tiller
    - deploy
  environment:
    name: production
    url: https://$PRODUCTION_HOST.$KUBE_INGRESS_BASE_DOMAIN
  dependencies: []
  only:
    refs:
      - production
    kubernetes: active

.deployment_test: &deployment_test
  stage: test
  interruptible: true
  image: python:alpine
  script:
    - check_kube_domain
    - install_dependencies
    - ensure_namespace
    - set_up_for_running_test_plan
    - run_all_test_plan
  dependencies: []

deployment_test_production:
  <<: *deployment_test
  environment:
    name: production
    url: https://$PRODUCTION_HOST.$KUBE_INGRESS_BASE_DOMAIN
  only:
    refs:
      - production
    kubernetes: active

deployment_test_staging:
  <<: *deployment_test
  environment:
    name: staging
    url: https://$STAGING_HOST.$KUBE_INGRESS_BASE_DOMAIN
  only:
    refs:
      - master
    kubernetes: active

deployment_test_demo:
  <<: *deployment_test
  environment:
    name: demo
    url: https://$DEMO_HOST.$KUBE_INGRESS_BASE_DOMAIN
  only:
    refs:
      - demo
    kubernetes: active

.deployment_test_review: &deployment_test_review
  stage: test
  image: python:alpine
  environment:
    name: review/$CI_COMMIT_REF_NAME
    url: https://$BASE_HOST_NAME-$CI_COMMIT_REF_SLUG.$KUBE_INGRESS_BASE_DOMAIN
    on_stop: stop_review
  dependencies: []
  only:
    refs:
      - /^dev-branch-[1-9]$/
    kubernetes: active

deployment_client_test_review:
  <<: *deployment_test_review
  script:
    - check_kube_domain
    - install_dependencies
    - ensure_namespace
    - set_up_for_running_test_plan
    - run_client_test_plan

deployment_server_test_review:
  <<: *deployment_test_review
  script:
    - check_kube_domain
    - install_dependencies
    - ensure_namespace
    - set_up_for_running_test_plan
    - run_server_test_plan

deployment_ciba_test_review:
  <<: *deployment_test_review
  script:
    - check_kube_domain
    - install_dependencies
    - ensure_namespace
    - set_up_for_running_test_plan
    - run_ciba_test_plan

deployment_local_test_review:
  stage: test
  image: docker:latest
  services:
    - docker:dind
  needs: ["build"]
  dependencies: []
  script:
    - install_test_dependencies
    - apk add docker-compose
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml pull
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml build --pull
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml up --detach httpd
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml run test
  after_script:
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml logs --tail="all" server > $CI_PROJECT_DIR/server.log
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml exec -T mongodb mongodump --db=test_suite --archive=/data/db/mongodb-dump.gz --gzip
    - docker-compose -f $CI_PROJECT_DIR/docker-compose-localtest.yml down
  dependencies:
    - build
  artifacts:
    when: always
    paths:
      - server.log
      - mongo/data/mongodb-dump.gz

# ---------------------------------------------------------------------------

.auto_devops: &auto_devops |
  # Auto DevOps variables and functions
  [[ "$TRACE" ]] && set -x
  export CI_APPLICATION_REPOSITORY=gcr.io/$GCP_PROJECT_ID/$CI_COMMIT_REF_SLUG
  export CI_APPLICATION_TAG=$CI_COMMIT_SHA
  export CI_CONTAINER_NAME=ci_job_build_${CI_JOB_ID}
  export TILLER_NAMESPACE=$KUBE_NAMESPACE
  export HELM_HOST="localhost:44134"

  function codeclimate() {
    cc_opts="--env CODECLIMATE_CODE="$PWD" \
             --volume "$PWD":/code \
             --volume /var/run/docker.sock:/var/run/docker.sock \
             --volume /tmp/cc:/tmp/cc"

    docker run ${cc_opts} codeclimate/codeclimate analyze -f json src > codeclimate.json
  }

  function deploy() {
    track="${1-stable}"
    name="$CI_ENVIRONMENT_SLUG"

    if [[ "$track" != "stable" ]]; then
      name="$name-$track"
    fi

    replicas="1"
    service_enabled="false"

    env_track=$( echo $track | tr -s  '[:lower:]'  '[:upper:]' )
    env_slug=$( echo ${CI_ENVIRONMENT_SLUG//-/_} | tr -s  '[:lower:]'  '[:upper:]' )

    if [[ "$track" == "stable" ]]; then
      # for stable track get number of replicas from `PRODUCTION_REPLICAS`
      eval new_replicas=\$${env_slug}_REPLICAS
      service_enabled="true"
    else
      # for all tracks get number of replicas from `CANARY_PRODUCTION_REPLICAS`
      eval new_replicas=\$${env_track}_${env_slug}_REPLICAS
    fi
    if [[ -n "$new_replicas" ]]; then
      replicas="$new_replicas"
    fi

    node_selector=""

    if [[ "$CI_COMMIT_BRANCH" == "production" ]]; then
      node_selector="--set nodeSelector.environment=production \
        --set tolerations[0].effect=NoSchedule \
        --set tolerations[0].key=dedicated \
        --set tolerations[0].operator=Equal \
        --set tolerations[0].value=production \
        --set mongodb.nodeSelector.environment=production \
        --set mongodb.tolerations[0].effect=NoSchedule \
        --set mongodb.tolerations[0].key=dedicated \
        --set mongodb.tolerations[0].operator=Equal \
        --set mongodb.tolerations[0].value=production"
    fi

    # Create OIDC credentials secrets
    kubectl delete secret oidc-gitlab-credentials \
      --namespace="$KUBE_NAMESPACE" \
      --ignore-not-found=true
    kubectl delete secret oidc-google-credentials \
      --namespace="$KUBE_NAMESPACE" \
      --ignore-not-found=true
    kubectl create secret generic oidc-gitlab-credentials \
      --namespace="$KUBE_NAMESPACE" \
      --from-literal=clientid="$OIDC_GITLAB_CLIENTID" \
      --from-literal=secret="$OIDC_GITLAB_SECRET"
    kubectl create secret generic oidc-google-credentials \
      --namespace="$KUBE_NAMESPACE" \
      --from-literal=clientid="$OIDC_GOOGLE_CLIENTID" \
      --from-literal=secret="$OIDC_GOOGLE_SECRET"

    helm upgrade --install \
      --wait \
      --set application.env_slug="$CI_ENVIRONMENT_SLUG" \
      --set application.path_slug="$CI_PROJECT_PATH_SLUG" \
      --set service.enabled="$service_enabled" \
      --set releaseOverride="$CI_ENVIRONMENT_SLUG" \
      --set image.repository="$CI_APPLICATION_REPOSITORY" \
      --set image.tag="$CI_APPLICATION_TAG" \
      --set image.pullPolicy=IfNotPresent \
      --set application.track="$track" \
      --set service.url="$CI_ENVIRONMENT_URL" \
      --set replicaCount="$replicas" \
      $node_selector \
      --namespace="$KUBE_NAMESPACE" \
      --version="$CI_PIPELINE_ID-$CI_JOB_ID" \
      "$name" \
      chart/

    echo -n "Waiting for mongodb pod to start"
    export MONGO_POD=""
    while [ -z "$MONGO_POD" ]; do echo -n .; sleep 5; get_mongo_pod; done; echo
    echo "Using pod: $MONGO_POD"
    echo -n "Connecting to mongodb"
    while ! kubectl exec $MONGO_POD -- mongo mongodb://localhost/test_suite --eval "db.version()" > /dev/null 2>&1; do echo -n .; sleep 1; done; echo
    echo "Inserting CI token"
    CI_TOKEN=$( dd bs=64 count=1 < /dev/urandom | base64 - | tr -d '\n' )
    kubectl exec $MONGO_POD -- \
      mongo mongodb://localhost/test_suite --eval \
        "db.API_TOKEN.update({ _id: \"ci_token\" }, { _id: \"ci_token\", owner: { sub: \"ci\", iss: \"${CI_ENVIRONMENT_URL}\" }, info: {}, token: \"${CI_TOKEN}\", expires: null }, { upsert: true })"
  }

  function get_mongo_pod() {
    MONGO_POD=`kubectl -n ${KUBE_NAMESPACE} get pod \
      -l app=mongodb -l release=${CI_ENVIRONMENT_SLUG} \
      --field-selector=status.phase=Running \
      -o template --template="{{(index .items 0).metadata.name}}" 2>&1` \
      || MONGO_POD=''
    export MONGO_POD
  }

  function install_dependencies() {
    apk add -U --upgrade openssl curl tar gzip bash ca-certificates git
    wget -q -O /etc/apk/keys/sgerrand.rsa.pub https://alpine-pkgs.sgerrand.com/sgerrand.rsa.pub
    wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/2.23-r3/glibc-2.23-r3.apk
    apk add glibc-2.23-r3.apk
    rm glibc-2.23-r3.apk

    curl -L -o /usr/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl
    chmod +x /usr/bin/kubectl
    kubectl version --client
  }

  function setup_docker() {
    if ! docker info &>/dev/null; then
      if [ -z "$DOCKER_HOST" -a "$KUBERNETES_PORT" ]; then
        export DOCKER_HOST='tcp://localhost:2375'
      fi
    fi
  }

  function ensure_namespace() {
    kubectl describe namespace "$KUBE_NAMESPACE" || kubectl create namespace "$KUBE_NAMESPACE"
  }

  function check_kube_domain() {
    if [ -z ${KUBE_INGRESS_BASE_DOMAIN+x} ]; then
      echo "In order to deploy, KUBE_INGRESS_BASE_DOMAIN must be set as a variable at the group or project level, or manually added in .gitlab-ci.yml"
      false
    else
      true
    fi
  }

  function install_build_dependencies() {
    apk -q add --no-cache --update --upgrade curl tar gzip make ca-certificates openssl python py-pip
    update-ca-certificates
    pip -q install docker-compose==1.23.2
    docker-compose --version

    curl https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.tar.gz | tar zx
    ./google-cloud-sdk/install.sh --usage-reporting=false --path-update=true
    ./google-cloud-sdk/bin/gcloud --quiet components update
  }

  function upload() {
    docker tag conformance-suite "$CI_APPLICATION_REPOSITORY:$CI_APPLICATION_TAG"

    echo "Logging in to container registry..."
    echo "$GCLOUD_SERVICE_KEY" | base64 -d > ${HOME}/gcloud-service-key.json
    ./google-cloud-sdk/bin/gcloud auth activate-service-account --key-file ${HOME}/gcloud-service-key.json

    echo "Pushing to GCR..."
    ./google-cloud-sdk/bin/gcloud docker -- push "$CI_APPLICATION_REPOSITORY:$CI_APPLICATION_TAG"
    echo ""
  }

  function install_test_dependencies() {
    echo "Installing extra dependencies"
    apk add -U openssh-client git
    apk add --update nodejs nodejs-npm
    eval $(ssh-agent -s)
    echo "$SSH_PRIVATE_KEY" | ssh-add -
    cd ..
    GIT_SSH_COMMAND="ssh -o StrictHostKeyChecking=no" git clone git@gitlab.com:openid/conformance-suite-private.git
    cd conformance-suite-private
  }

  function set_up_for_running_test_plan() {
    install_test_dependencies
    pip install requests
    export CONFORMANCE_SERVER="${CI_ENVIRONMENT_URL}/"
    get_mongo_pod
    export CONFORMANCE_TOKEN=$(kubectl -n ${KUBE_NAMESPACE} exec ${MONGO_POD} -- mongo --quiet mongodb://localhost/test_suite --eval "db.API_TOKEN.findOne({ _id: \"ci_token\" }).token")
  }

  function run_all_test_plan() {
    echo "Running automated tests against $CONFORMANCE_SERVER"
    ../conformance-suite/.gitlab-ci/run-tests.sh
  }

  function run_client_test_plan() {
    echo "Running automated tests against $CONFORMANCE_SERVER"
    ../conformance-suite/.gitlab-ci/run-tests.sh --client-tests-only
  }

  function run_server_test_plan() {
    echo "Running automated tests against $CONFORMANCE_SERVER"
    ../conformance-suite/.gitlab-ci/run-tests.sh --server-tests-only
  }

  function run_ciba_test_plan() {
      echo "Running automated tests against $CONFORMANCE_SERVER"
      ../conformance-suite/.gitlab-ci/run-tests.sh --ciba-tests-only
    }

before_script:
  - *auto_devops
